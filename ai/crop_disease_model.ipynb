{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15fa7c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy image dataset created successfully!\n",
      "Yield dataset already exists.\n",
      "Found 15 images belonging to 3 classes.\n",
      "Found 15 images belonging to 3 classes.\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Documents\\GitHub\\FarmIQ\\FarmIQ\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\ASUS\\Documents\\GitHub\\FarmIQ\\FarmIQ\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 - 1s - 143ms/step - accuracy: 0.0000e+00 - loss: 1.4769 - val_accuracy: 0.3333 - val_loss: 1.1150\n",
      "Epoch 2/3\n",
      "8/8 - 0s - 14ms/step - accuracy: 0.3333 - loss: 1.1081 - val_accuracy: 0.3333 - val_loss: 1.1060\n",
      "Epoch 3/3\n",
      "8/8 - 0s - 13ms/step - accuracy: 0.3333 - loss: 1.1127 - val_accuracy: 0.3333 - val_loss: 1.1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model saved at ./backend/models/disease_model.h5\n",
      "Yield model saved at ./backend/models/yield_model.pkl\n",
      "Predicted yield: 116.0\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Predicted disease class for dummy image: healthy\n"
     ]
    }
   ],
   "source": [
    "# farmiq_complete.py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib\n",
    "\n",
    "# =========================\n",
    "# Part 1: Create Dummy Image Dataset for Disease Detection\n",
    "# =========================\n",
    "IMG_SIZE = (64, 64)\n",
    "BATCH_SIZE = 2\n",
    "classes = ['healthy', 'diseased1', 'diseased2']\n",
    "\n",
    "base_dir = './data/plant_village'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "\n",
    "for directory in [train_dir, val_dir]:\n",
    "    for cls in classes:\n",
    "        os.makedirs(os.path.join(directory, cls), exist_ok=True)\n",
    "\n",
    "def create_dummy_images(folder, num_images=5):\n",
    "    for cls in classes:\n",
    "        class_folder = os.path.join(folder, cls)\n",
    "        if len(os.listdir(class_folder)) == 0:  # Avoid recreating if already exists\n",
    "            for i in range(num_images):\n",
    "                img = Image.fromarray(np.random.randint(0, 256, (64, 64, 3), dtype=np.uint8))\n",
    "                img.save(os.path.join(class_folder, f'{cls}_{i}.png'))\n",
    "\n",
    "create_dummy_images(train_dir)\n",
    "create_dummy_images(val_dir)\n",
    "print(\"Dummy image dataset created successfully!\")\n",
    "\n",
    "# =========================\n",
    "# Part 2: Create Dummy CSV Dataset for Yield Prediction\n",
    "# =========================\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "csv_path = './data/yield_data.csv'\n",
    "if not os.path.exists(csv_path):\n",
    "    data = pd.DataFrame({\n",
    "        'soil_moisture': [20, 30, 25, 35, 40],\n",
    "        'temperature': [25, 27, 26, 28, 30],\n",
    "        'humidity': [60, 65, 63, 70, 68],\n",
    "        'yield': [100, 120, 110, 130, 140]\n",
    "    })\n",
    "    data.to_csv(csv_path, index=False)\n",
    "    print(\"Dummy yield_data.csv created successfully.\")\n",
    "else:\n",
    "    print(\"Yield dataset already exists.\")\n",
    "\n",
    "# =========================\n",
    "# Part 3: Build and Train CNN for Disease Detection\n",
    "# =========================\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=(64,64,3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(classes), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.fit(train_generator, validation_data=val_generator, epochs=3, verbose=2)\n",
    "\n",
    "# Save CNN model\n",
    "os.makedirs('./backend/models', exist_ok=True)\n",
    "cnn_model_path = './backend/models/disease_model.h5'\n",
    "cnn_model.save(cnn_model_path)\n",
    "print(f\"CNN model saved at {cnn_model_path}\")\n",
    "\n",
    "# =========================\n",
    "# Part 4: Train Linear Regression for Yield Prediction\n",
    "# =========================\n",
    "data = pd.read_csv(csv_path)\n",
    "X = data[['soil_moisture', 'temperature', 'humidity']]\n",
    "y = data['yield']\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X, y)\n",
    "\n",
    "# Save LR model\n",
    "yield_model_path = './backend/models/yield_model.pkl'\n",
    "joblib.dump(lr_model, yield_model_path)\n",
    "print(f\"Yield model saved at {yield_model_path}\")\n",
    "\n",
    "# =========================\n",
    "# Part 5: Test Predictions\n",
    "# =========================\n",
    "# Test yield prediction\n",
    "test_input = pd.DataFrame({\n",
    "    'soil_moisture': [28],\n",
    "    'temperature': [27],\n",
    "    'humidity': [65]\n",
    "})\n",
    "predicted_yield = lr_model.predict(test_input)\n",
    "print(\"Predicted yield:\", predicted_yield[0])\n",
    "\n",
    "# Test disease prediction (dummy image)\n",
    "dummy_img_path = './data/plant_village/val/healthy/healthy_0.png'\n",
    "from tensorflow.keras.preprocessing import image\n",
    "img = image.load_img(dummy_img_path, target_size=IMG_SIZE)\n",
    "img_array = image.img_to_array(img)/255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "pred_class = cnn_model.predict(img_array)\n",
    "predicted_class_index = np.argmax(pred_class)\n",
    "predicted_class_name = classes[predicted_class_index]\n",
    "print(\"Predicted disease class for dummy image:\", predicted_class_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
